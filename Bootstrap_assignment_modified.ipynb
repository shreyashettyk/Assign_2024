{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
    "\n",
    "#importing random module \n",
    "from random import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes\n",
    "\n",
    "* <font color='red'><b> Note - While selecting the random 60% datapoints from the whole data, make sure that the selected datapoints are all exclusive, repetition is not allowed. </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6rShd89t552"
   },
   "source": [
    "## <font color='red'><b>A few key points</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdgTUXTouHEd"
   },
   "source": [
    "* Remember that the datapoints used for calculating MSE score contain some datapoints that were initially used while training the base learners (the 60% sampling). This makes these datapoints partially seen (i.e. the datapoints used for calculating the MSE score are a mixture of seen and unseen data).\n",
    "Whereas, the datapoints used for calculating OOB score have only the unseen data. This makes these datapoints completely unseen and therefore appropriate for testing the model's performance on unseen data.\n",
    "\n",
    "* Given the information above, if your logic is correct, the calculated MSE score should be less than the OOB score.\n",
    "\n",
    "* The MSE score must lie between 0 and 10.\n",
    "* The OOB score must lie between 10 and 35.\n",
    "\n",
    "* The difference between the left nad right confidence-interval values must not be more than 10. Make sure this is true for both MSE and OOB confidence-interval values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/OfcFrUP.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "    Selecting_rows = sample(list(range(0,x.shape[0])),303) #select 303 row indices from 506 indices at random without replacement\n",
    "    Replacing_rows = choices(Selecting_rows,k=203)  #select 203 row indices out of 303 indices at random with repalcement\n",
    "    number_of_columns = choice(list(range(3,14)))  #select the number of columns for each row sample\n",
    "    Selecting_columns = sample(list(range(0,13)),number_of_columns) #select the column indices without replacement. The number of column indces chosen must be equal to the number of columns (min = 3)\n",
    "\n",
    "    sample_data = input_data[Selecting_rows,:][:,Selecting_columns] #create a row sample using the selected row indices and colum indiced\n",
    "    target_of_sample_data = y[Selecting_rows] #get the corresponding target data\n",
    "    \n",
    "    #Replicating Data \n",
    "    \n",
    "    Replicated_sample_data = input_data[Replacing_rows,:][:,Selecting_columns] #replicate the row samples\n",
    "    target_of_replicated_sample_data = target_data[Replacing_rows]\n",
    "    \n",
    "    #Concatenating data\n",
    "    \n",
    "    final_sample_data = np.vstack([sample_data,Replicated_sample_data]) #stack the row samples (picked with and without replacement)\n",
    "    final_target_data = np.vstack([target_of_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1)]) #stack the target data\n",
    "    print(final_sample_data.shape,final_target_data.shape,len(Selecting_rows),len(Selecting_columns))\n",
    "    return final_sample_data,final_target_data,Selecting_rows,Selecting_columns  #return the final data sample,final target data,the row index without replacement and the column indices\n",
    "    \n",
    "    \n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 9) (506, 1) 303 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "def gen_data_30_base_models(number_samples):\n",
    "    #generating a data of 506 rows for each of the 30 base learners\n",
    "    for i in range(number_samples):\n",
    "        print(i)\n",
    "        a,b,c,d = generating_samples(x,y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(506, 11) (506, 1) 303 11\n",
      "1\n",
      "(506, 7) (506, 1) 303 7\n",
      "2\n",
      "(506, 12) (506, 1) 303 12\n",
      "3\n",
      "(506, 12) (506, 1) 303 12\n",
      "4\n",
      "(506, 10) (506, 1) 303 10\n",
      "5\n",
      "(506, 5) (506, 1) 303 5\n",
      "6\n",
      "(506, 10) (506, 1) 303 10\n",
      "7\n",
      "(506, 8) (506, 1) 303 8\n",
      "8\n",
      "(506, 13) (506, 1) 303 13\n",
      "9\n",
      "(506, 11) (506, 1) 303 11\n",
      "10\n",
      "(506, 11) (506, 1) 303 11\n",
      "11\n",
      "(506, 6) (506, 1) 303 6\n",
      "12\n",
      "(506, 8) (506, 1) 303 8\n",
      "13\n",
      "(506, 12) (506, 1) 303 12\n",
      "14\n",
      "(506, 5) (506, 1) 303 5\n",
      "15\n",
      "(506, 8) (506, 1) 303 8\n",
      "16\n",
      "(506, 12) (506, 1) 303 12\n",
      "17\n",
      "(506, 7) (506, 1) 303 7\n",
      "18\n",
      "(506, 12) (506, 1) 303 12\n",
      "19\n",
      "(506, 13) (506, 1) 303 13\n",
      "20\n",
      "(506, 7) (506, 1) 303 7\n",
      "21\n",
      "(506, 13) (506, 1) 303 13\n",
      "22\n",
      "(506, 5) (506, 1) 303 5\n",
      "23\n",
      "(506, 6) (506, 1) 303 6\n",
      "24\n",
      "(506, 8) (506, 1) 303 8\n",
      "25\n",
      "(506, 13) (506, 1) 303 13\n",
      "26\n",
      "(506, 8) (506, 1) 303 8\n",
      "27\n",
      "(506, 6) (506, 1) 303 6\n",
      "28\n",
      "(506, 5) (506, 1) 303 5\n",
      "29\n",
      "(506, 12) (506, 1) 303 12\n"
     ]
    }
   ],
   "source": [
    "gen_data_30_base_models(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_base_models(number_sample):\n",
    "    #Train each of the base learner using the data prepared and store all the base lerners in a list\n",
    "    model_list = []\n",
    "    for i in range(number_samples):\n",
    "        input_data = list_input_data[i]\n",
    "        target_data = list_output_data[i].flatten()\n",
    "\n",
    "        dt = DecisionTreeRegressor(max_depth=None)\n",
    "        dt.fit(input_data,target_data)\n",
    "\n",
    "        model_list.append(dt)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = gen_base_models(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(input_data):\n",
    "    '''Function to prdict a bagged output given a datapoint'''\n",
    "    final_output_list = []\n",
    "    for row in input_data:\n",
    "        \n",
    "        i = 0\n",
    "        output_list = []\n",
    "        for model in model_list:\n",
    "            \n",
    "            data = row[list_selected_columns[i]]\n",
    "            output_value = model.predict(data.reshape(1,-1))\n",
    "            output_list.append(output_value)\n",
    "            i+=1\n",
    "        final_bagged_output = np.median(np.array(output_list))\n",
    "        final_output_list.append(final_bagged_output)\n",
    "    return final_output_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_list = predict_outcome(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_computation(actual,pred):\n",
    "    mse = mean_squared_error(actual,pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on train data is  0.09695158102766804\n"
     ]
    }
   ],
   "source": [
    "mse = MSE_computation(y,bagged_list)\n",
    "print('The MSE on train data is ',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_input():\n",
    "    #computing the bagged output on oob data and store the outcome in a list\n",
    "    input_data_index = list(range(0,x.shape[0]))\n",
    "\n",
    "    data_index = 0\n",
    "    final_oob_list = []\n",
    "    for row in x:\n",
    "        pred_outcome_list  = []\n",
    "        i = 0\n",
    "        for model in model_list:\n",
    "            model_trained_rows = (list_selected_row[i])\n",
    "            if data_index not in model_trained_rows:\n",
    "                data = row[list_selected_columns[i]]\n",
    "                pred_value = model.predict(data.reshape(1,-1))\n",
    "                pred_outcome_list.append(pred_value)\n",
    "            i+=1\n",
    "        print('number of models which gave prediction ',len(pred_outcome_list))\n",
    "        final_pred_value = np.median(np.array(pred_outcome_list))\n",
    "        final_oob_list.append(final_pred_value)\n",
    "\n",
    "        data_index+=1\n",
    "        \n",
    "    return final_oob_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oob_list = oob_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on doing oob computation is  11.84766304347826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#This is same as caluclationg  the MSE between actual data points and oob calculated\n",
    "print('MSE on doing oob computation is ',MSE_computation(y,final_oob_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = []\n",
    "oob_score_list = []\n",
    "for cnt in tqdm(range(35)):\n",
    "    list_input_data =[] #list to store overall input\n",
    "    list_output_data =[] #list to store overall target\n",
    "    list_selected_row= [] #list to store uniquely selected rows\n",
    "    list_selected_columns=[] #list to store unique selected columns (min =3,max=13)\n",
    "    \n",
    "    gen_data_30_base_models(30)  #first generate row sampled and column sampled data for 30 base learners\n",
    "    model_list = gen_base_models(30) #build 30 models each of them trained with respective data\n",
    "    \n",
    "    bagged_list = predict_outcome(x) #predict the value on each train datapoint\n",
    "    mse = MSE_computation(y,bagged_list) #compute MSE\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    final_oob_list = oob_input() #predict outcome on each OOB datapoint\n",
    "    oob_score = MSE_computation(y,final_oob_list) #compute MSE\n",
    "    oob_score_list.append(oob_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check(iterations):\n",
    "    assert(len(mse_list) == iterations and len(oob_score_list) == iterations)\n",
    "    return True\n",
    "check(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI of MSE across 35 samples is [ 0.08057169593983873 , 0.13338769798516398 ]\n",
      "The 95% CI of OOB score across 35 samples is [ 8.786385308361155 , 17.761059773656793 ]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "mean_oob_score = np.mean(oob_score_list)\n",
    "std_oob_score = np.mean(oob_score_list)\n",
    "\n",
    "lower_limit_mse = mean_mse-(2*(std_mse/(math.sqrt(len(mse_list)))))\n",
    "upper_limit_mse = mean_mse+(2*(std_mse/(math.sqrt(len(mse_list)))))\n",
    "\n",
    "lower_limit_oob = mean_oob_score-(2*(std_oob_score/(math.sqrt(len(oob_score_list)))))\n",
    "upper_limit_oob = mean_oob_score+(2*(std_oob_score/(math.sqrt(len(oob_score_list)))))\n",
    "\n",
    "print('The 95% CI of MSE across 35 samples is [',lower_limit_mse,',',upper_limit_mse,']')\n",
    "print('The 95% CI of OOB score across 35 samples is [',lower_limit_oob,',',upper_limit_oob,']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE check\n",
      "OOB check\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def limit_check(ll,ul):\n",
    "    assert((ul-ll) <= 10)\n",
    "    return True\n",
    "\n",
    "print('MSE check')\n",
    "limit_check(lower_limit_mse,upper_limit_mse)\n",
    "print('OOB check')\n",
    "limit_check(lower_limit_oob,upper_limit_oob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final predicted value from the Decision Tree Regressor is  19.1\n"
     ]
    }
   ],
   "source": [
    "#use the custom Bagging regressor on a given query point\n",
    "xq= np.array([[0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]])\n",
    "final_list = predict_outcome(xq)\n",
    "print('The final predicted value from the Decision Tree Regressor is ',final_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIcax45hWKT-"
   },
   "source": [
    "***Observation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK-1**\n",
    "\n",
    "1. Upon running the bagging model for one set of randomly generated row samples and column samples we got a MSE of  0.09695158102766804 on the training data and OOB score of 11.84766304347826\n",
    "2. The MSE on the train data is very small as some of the base models would have already seen the train data point as part \n",
    "of the randomly chosen sample\n",
    "3. The MSE obtained from OOB data is also low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK-2**\n",
    "\n",
    "1. The house price predicted for the given xq is 19.1 . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK-3**\n",
    "\n",
    "1. Upon running 35 iterations of the steps mentioned in Task -1 we come up with a list of 35 values of MSE over train data and 35 values of MSE over OOB data\n",
    "2. We see that among 35 samples, 95% of them have MSE over train data lying between [ 0.08057169593983873 , 0.13338769798516398 ]\n",
    "3. We see that among 35 samples, 95% of them have MSE over OOB data lying between [ 8.786385308361155 , 17.761059773656793 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
